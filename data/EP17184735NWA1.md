# (11)(19) **EP 3 441 829 A1**
## (12) **EUROPEAN PATENT APPLICATION**
## (43) Date of publication:<br>**13.02.2019 Bulletin 2019/07**
## (21) Application number: **17184735.3**
## (22) Date of filing: **08.08.2017**
## (51) Int Cl.:
+ ***G05B 17/02 <sup>(2006.01)</sup>***
+ ***G05B 13/02 <sup>(2006.01)</sup>***
+ ***G05B 13/04 <sup>(2006.01)</sup>***
***
## (54)
+ **SYSTEMZUSTANDSVORHERSAGE**
+ **SYSTEM STATE PREDICTION**
+ **PRÉDICTION D'ÉTAT D'UN SYSTÈME**
***
## (84) Designated Contracting States:<br>**AL AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO RS SE SI SK SM TR**
## (43) Date of publication of application: 13.02.2019 Bulletin 2019/07
## (71) Applicant:
+ **Siemens Aktiengesellschaft<br>80333 München (DE)**
## (72) Inventor:
+ **Allmaras, Moritz<br>81673 München (DE)**
+ **Obst, Birgit<br>80935 München (DE)**
<br><br><u>Remarks:</u>
+ Missing drawings filed in accordance with Rule 56(2) EPC.
+ Amended claims in accordance with Rule 137(2) EPC.
***
(57) 
A method comprises steps of providing a state space model of behaviour of a physical system, the model including covariances for state transition and measurement errors; providing a data based regression model for prediction of state variables of the physical system; observing a state vector comprising state variables of the physical system; determining a prediction vector of state variables based on the state vector, using the regression model; and combining information from the state space model with predictions from the regression model through a Bayesian filter.
<img id="iaf01" file="imgaf001.tif" wi="139" he="110" img-content="drawing" img-format="tif"/><br>
***
**Description**
<br><br>System State Prediction<br><br>
**[0001]**&nbsp;&nbsp;Present invention concerns the prediction of the future state of a dynamical system. More particularly present invention concerns the combination of different models for state prediction.<br>

<br><br>Background of the Invention<br><br>
**[0002]**&nbsp;&nbsp;During start-up, an asynchronous electric motor converts a considerable portion of the electric current that flows through it into heat, which may build up sharply on a pole shoe of the rotor. This happens due to slippage of magnetic fields between the stator and the rotor while the rotor rotates slower than the electrical frequency dictates. Such excess heat can cause structural damage to the motor and therefore needs to be closely monitored. Since the pole shoe is part of the rotating assembly, a sensor for direct temperature measurement of the pole shoe surface cannot be placed in a production device due to the high associated cost. Hence, a simulation model for calculation and prediction of these temperatures may be set up.<br>

**[0003]**&nbsp;&nbsp;Prediction of system state is traditionally performed using either a physical model or a data based regression model. The physical model is susceptible to modelling errors and needs calibration. The data driven model can only predict behaviour that can be directly observed in real systems. A data driven model will produce poor results if the space of possible control inputs is not densely sampled in the recorded data.<br>

**[0004]**&nbsp;&nbsp;It is therefore a task of the present invention to provide an improved technique for predicting the state vector of a physical system.<!-- EPO <DP n="2"> --><br>

<br><br>Disclosure of the Invention<br><br>
**[0005]**&nbsp;&nbsp;A method comprises steps of providing a state space model of behaviour of a physical system, the model including covariances for state transition and measurement errors; providing a data based regression model for prediction of state variables of the physical system; observing a state vector comprising state variables of the physical system; determining a prediction vector of state variables based on the state vector, using the regression model; and combining information from the state space model with predictions from the regression model through a Bayesian filter.<br>

**[0006]**&nbsp;&nbsp;The method may be used to make predictions for one or more state variables of the state vector. Behaviour of the physical system may thus be forecast and a potentially dangerous situation may be identified even before it occurs. A countermeasure to prevent that situation may be conducted in time. Should the covariances for state transition and measurement errors not be available, estimations thereof may be used.<br>

**[0007]**&nbsp;&nbsp;The method combines a mathematical model of system behaviour based on the physics of the underlying process and measurement data collected during operation of actual instances of the real system. Due to the combination, in practical applications the prediction accuracy of the described method is expected to be improved when compared to the prediction accuracy achieved by using a model-driven approach by itself. On the other hand, data-driven approaches by themselves do not allow prediction of unobserved state variables.<br>

**[0008]**&nbsp;&nbsp;The physical system is preferred to be a time-discrete linear time-invariant system but other systems can also be addressed, as will be shown below. Note that the system must be physical for the physical model to make sense. The system may for instance represent a mechanism for carrying out a predetermined technical process or a motor, especially an asynchronous electric motor.<!-- EPO <DP n="3"> --><br>

**[0009]**&nbsp;&nbsp;The Bayesian filter may be realized by a Kalman filter. The Kalman filter can be used for making a prediction for the state vector by carrying out only steps of predicting an estimate and predicting a covariance for each time step. The Kalman filter will be adequate to a Bayes filter if the filter variables are linear and normally distributed. Kalman filtering is state-of-the-art and can be done with moderate computational means. Processing libraries are available for a broad range of processing environments.<br>

**[0010]**&nbsp;&nbsp;The Bayesian filter may be realized through an Extended Kalman filter. This may be especially useful if the physical system is nonlinear. The Extended Kalman filter (EKF) is the nonlinear version of the Kalman filter which linearises about an estimate of the current mean and covariance. In the case of well defined transition models, the EKF has been considered the de facto standard in the theory of nonlinear state estimation. The EKF may therefore allow for both linear and nonlinear variables, making it more flexible and versatile.<br>

**[0011]**&nbsp;&nbsp;The Bayesian filter may also comprise a particle filter. This may be especially advantageous if a distribution of the measurement errors is non-Gaussian. The particle filter is also called a Sequential Monte Carlo (SMC) method for solving filtering problems in Bayesian filter inference.<br>

**[0012]**&nbsp;&nbsp;The regression model may comprise a trained recurrent neural network (RNN). The RNN may be used to predict system outputs for given control inputs. The RNN may be trained offline and deployed to the place where the method is carried out. In an RNN, connections between units generally form a directed cycle, so that the RNN may exhibit dynamic temporal behavior. Unlike feedforward neural networks, RNNs can use their internal memory to process arbitrary sequences of inputs. This ability makes an RNN a favourable choice for the regression model. In other embodiments, a different machine learning method that allows time series regression from a given input<!-- EPO <DP n="4"> --> signal may also be used.<br>

**[0013]**&nbsp;&nbsp;Especially if the physical system is time continuous, the Recurrent Neural Network may be interpolated between discrete time steps and the Bayesian filter may comprise a Continuous Kalman Filter. In that case, the state equation of the state space system model may be continuous, too.<br>

**[0014]**&nbsp;&nbsp;An apparatus comprises an interface for observing a state vector comprising state variables in a physical system; and processing means adapted to carry out above-described method completely or in part. To this ends, the described method may be formulated as a computer program product with program code means. Advantages or features of the method may apply to the apparatus and vice versa.<br>

<br><br>Brief Summary of the Enclosed Figures<br><br>
**[0015]**&nbsp;&nbsp;The above-described properties, features and advantages of present invention as well as the way they are achieved will be made clearer and better understandable in the light of the following discussion, making reference to exemplary embodiments shown in accompanying figures, in which
<ul id="ul0001" list-style="none" compact="compact">
<li><figref idref="f0001">Fig. 1</figref> shows schematically how a Kalman filter may be used for state prediction;</li>
<li><figref idref="f0002">Fig. 2</figref> shows a schematic representation of a method for providing improved state information prediction; and</li>
<li><figref idref="f0003">Fig. 3</figref> shows an exemplary physical system and an exemplary apparatus for prediction of a state of the physical system.</li>
</ul><br>

<br><br>Detailed Exemplary Embodiments of the Invention<br><br>
**[0016]**&nbsp;&nbsp;Prediction of system state is traditionally performed using one of the following approaches:
<ol id="ol0001" ol-style="">
<li>i) A mathematical model is derived from the physical system behaviour and numerically simulated forward in time, starting<!-- EPO <DP n="5"> --> from a known initial state and using given future system inputs.</li>
<li>ii) Measurements are collected from a real system and a data-based regression model is constructed that allows prediction of the system output given its inputs.</li>
</ol><br>

**[0017]**&nbsp;&nbsp;Approach i) is susceptible to modelling errors, i.e. the model not describing the behaviour of the actual real-world system with sufficient accuracy. Deriving a model that covers all relevant behaviour of a real world system with respect to the intended application can be a challenging problem. Calibration needs to be performed in order to adapt model parameters to match observed system behaviour as accurately as possible. But even then, any unmodelled dynamics in the system will substantially degrade long-term prediction performance of the model-driven approach.<br>

**[0018]**&nbsp;&nbsp;In Approach ii), machine learning techniques are used to train a data-driven model in order to learn the behaviour of the system from recorded measurements of system output for given control inputs. This approach does not suffer from errors due to unmodelled dynamics, but on the other hand can only predict behaviour that can be directly observed in real systems. Any part of the system state that is not observed through outputs cannot be targeted by data-driven methods without a model of how these states are connected to observable quantities. In addition, if the space of possible control inputs is not densely sampled in the recorded data, a data-driven approach will produce poor prediction results for control inputs that are far from the inputs covered by the recorded data. Also, the accuracy of data-driven prediction approaches inherently depends on the accuracy of measurements.<br>

**[0019]**&nbsp;&nbsp;The method described herein combines approaches i) and ii) to allow more accurate state predictions than would be possible by using either of the two approaches by themselves.<!-- EPO <DP n="6"> --><br>

**[0020]**&nbsp;&nbsp;Ingredients to the proposed method are the following:
<ol id="ol0002" compact="compact" ol-style="">
<li>a) a state space description of the system behaviour including covariances for state-transition and measurement errors (or estimates thereof),</li>
<li>b) a data-based regression model for predicting system outputs to given control inputs,</li>
<li>c) a Bayesian filter method for combining information from the state space model with predictions from the regression model.</li>
</ol><br>

**[0021]**&nbsp;&nbsp;The method makes use of these ingredients to predict system state over a time range in the future for which the control input is given. In the following, for clarity of exposition, the method is detailed using specific variants for a), b) and c). However, it is noted that the method is applicable in a much more general setting.<br>

**[0022]**&nbsp;&nbsp;In particular, for the detailed exposition we assume that
<ul id="ul0002" list-style="dash" compact="compact">
<li>The system under consideration is a time-discrete linear time-invariant (LTI) system, in which all random variables are normally distributed,</li>
<li>For the Bayesian filter the well-known Kalman-filter method is applied,</li>
<li>A recurrent neural network is trained using historic measurements to predict system outputs for given control inputs.</li>
</ul><br>

<br><br>State-space system model<br><br>
**[0023]**&nbsp;&nbsp;A time-discrete LTI system can be described by the equations: <maths id="math0001" num=""><math display="block"><mrow><msub><mi>x</mi><mi>k</mi></msub><mo>=</mo><msub><mi mathvariant="italic">Ax</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi mathvariant="italic">Bu</mi><mi>k</mi></msub><mo>+</mo><msub><mi>w</mi><mi>k</mi></msub></mrow></math><img id="ib0001" file="imgb0001.tif" wi="39" he="5" img-content="math" img-format="tif"/></maths> <maths id="math0002" num=""><math display="block"><mrow><msub><mi>z</mi><mi>k</mi></msub><mo>=</mo><msub><mi mathvariant="italic">Hx</mi><mi>k</mi></msub><mo>+</mo><msub><mi>v</mi><mi>k</mi></msub></mrow></math><img id="ib0002" file="imgb0002.tif" wi="25" he="5" img-content="math" img-format="tif"/></maths><!-- EPO <DP n="7"> --><br>

**[0024]**&nbsp;&nbsp;Here, <i>x<sub>k</sub></i> denotes the system state at time step <i>k, A</i> is the state-transition matrix, <i>B</i> the control matrix, <i>u<sub>k</sub></i> the input and <i>w<sub>k</sub></i> the process noise at time step <i>k</i>. Likewise, in the output equation, <i>z<sub>k</sub></i> are the measurements, <i>H</i> the output matrix and <i>v<sub>k</sub></i> the measurement noise at time step <i>k</i>.<br>

**[0025]**&nbsp;&nbsp;We assume that the noise terms <i>w<sub>k</sub></i> and <i>v<sub>k</sub></i> are mean-free normally distributed random variables with covariance matrix <i>Q<sub>k</sub></i> and <i>R<sub>k</sub></i> respectively: <i>v<sub>k</sub></i>∼<i>N</i>(0<i>,Q<sub>k</sub></i>)<i>, w<sub>k</sub></i>∼<i>N</i>(0,<i>R<sub>k</sub></i>)<i>.</i><br>

**[0026]**&nbsp;&nbsp;The problem of state prediction can now be stated as follows: Given an initial state <i>x</i><sub>0</sub> and known control inputs <i>u<sub>j</sub></i> for <i>j</i> in {1,..<i>K</i>}, predict the system state <i>x<sub>j</sub></i> for each <i>j</i> in {1,..<i>K</i>}.<br>

**[0027]**&nbsp;&nbsp;In addition to the state space model given above, it is assumed that large amounts of historic data from existing instances of the real-world system are available. This historic data consists of a large number <i>M</i> of sets of inputs <maths id="math0003" num=""><math display="inline"><mrow><msubsup><mfenced open="{" close="}"><msubsup><mi>u</mi><mi>j</mi><mi>s</mi></msubsup></mfenced><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup></mrow></math><img id="ib0003" file="imgb0003.tif" wi="12" he="8" img-content="math" img-format="tif" inline="yes"/></maths> with corresponding measurements of outputs <maths id="math0004" num=""><math display="inline"><mrow><msubsup><mfenced open="{" close="}"><msubsup><mi>z</mi><mi>j</mi><mi>s</mi></msubsup></mfenced><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup><mo>:</mo></mrow></math><img id="ib0004" file="imgb0004.tif" wi="15" he="10" img-content="math" img-format="tif" inline="yes"/></maths> <maths id="math0005" num=""><math display="inline"><mrow><msubsup><mfenced open="{" close="}"><msup><mi>U</mi><mi>s</mi></msup></mfenced><mrow><mi>s</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></msubsup><mo>,</mo></mrow></math><img id="ib0005" file="imgb0005.tif" wi="15" he="9" img-content="math" img-format="tif" inline="yes"/></maths> where <maths id="math0006" num=""><math display="inline"><mrow><msup><mi>U</mi><mi>s</mi></msup><mo>=</mo><mrow><mo>⌊</mo><msubsup><mfenced open="{" close="}"><msubsup><mi>u</mi><mi>j</mi><mi>x</mi></msubsup></mfenced><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup><mo>,</mo><msubsup><mfenced open="{" close="}"><msubsup><mi>z</mi><mi>j</mi><mi>s</mi></msubsup></mfenced><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup><mo>⌋</mo></mrow><mn>.</mn></mrow></math><img id="ib0006" file="imgb0006.tif" wi="37" he="10" img-content="math" img-format="tif" inline="yes"/></maths><br>

<br><br>Kalman filter<br><br>
**[0028]**&nbsp;&nbsp;<figref idref="f0001">Figure 1</figref> shows schematically a method 100 of using a Kalman-filter for state prediction. A present point in time is indicated as a broken line between times k and k+1. Times k, k-1 and lower are considered to lie in the past and times k+1, k+2 and higher in the future.<br>

**[0029]**&nbsp;&nbsp;The Kalman-filter method provides an estimator <i>x̂</i><sub><i>k</i>|<i>k</i></sub> for the system state at time <i>k</i> given measurements at time <i>k</i>. The algorithm consists of the following computational steps:<!-- EPO <DP n="8"> -->
<ul id="ul0003" list-style="dash" compact="compact">
<li>Predicted estimate: <i>x̂</i><sub><i>k</i>l<i>k</i>-1</sub> = <i>Ax̂</i><sub><i>k</i>l<i>k</i>-1</sub> + <i>Bu<sub>k</sub></i></li>
<li>Predicted covariance: <i>P</i><sub><i>k</i>l<i>k</i>-1</sub> = <i>AP</i><sub><i>k</i>-1|<i>k</i>-1</sub><i>A<sup>T</sup></i> + <i>Q</i><sub><i>k</i>-1</sub></li>
<li>Measurement residual: <i>ỹ<sub>k</sub> = z<sub>k</sub></i> -<i>Hx̂</i><sub><i>k</i>|<i>k</i>-1</sub></li>
<li>Residual covariance: <i>S<sub>k</sub></i> = <i>HP</i><sub>k|k-1</sub><i>H<sup>T</sup></i> + <i>R<sub>k</sub></i></li>
<li>Kalman gain matrix: <i>K<sub>k</sub> = P</i><sub><i>k</i>|<i>k</i>-1</sub><i>H<sup>T</sup></i>+ <i>R<sub>k</sub></i></li>
<li>Corrected prediction: <i>x̂</i><sub><i>k</i>|<i>k</i></sub> = <i>x̂</i><sub><i>k</i>|<i>k</i>-1</sub> + <i>K<sub>k</sub>ỹ<sub>k</sub></i></li>
<li>Corrected covariance: <i>P</i><sub><i>k</i>|<i>k</i></sub> (<i>I</i> - <i>K<sub>k</sub>H</i>)<i>P</i><sub><i>kk</i>-1</sub></li>
</ul><br>

**[0030]**&nbsp;&nbsp;Given previous state and current measurements, the Kalman-filter is known to compute the optimal estimate of the current state and its covariance. The Kalman-filter can also be used for predicting future states if only the first two prediction steps are carried out in each time step. However, in this case there is no correction from measurements being applied, and this leads to a rapid increase of the covariance of predicted states, indicating that the uncertainty of predicted state values increases rapidly with increasing time step.<br>

**[0031]**&nbsp;&nbsp;A schematic representation of a method for system state prediction is shown in <figref idref="f0002">Figure 2</figref>. As in <figref idref="f0001">Figure 1</figref>, a broken line symbolically separates a past (above) from a future (below).<br>

<br><br>Data-driven regression model for measurement prediction<br><br>
**[0032]**&nbsp;&nbsp;For the regression model, the available historic data <maths id="math0007" num=""><math display="inline"><mrow><msubsup><mfenced open="{" close="}"><msup><mi>U</mi><mi>s</mi></msup></mfenced><mrow><mi>s</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></msubsup></mrow></math><img id="ib0007" file="imgb0007.tif" wi="12" he="8" img-content="math" img-format="tif" inline="yes"/></maths> is split into training <maths id="math0008" num=""><math display="inline"><mrow><msubsup><mfenced open="{" close="}"><msup><mi>U</mi><mi>s</mi></msup></mfenced><mrow><mi>s</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msubsup></mrow></math><img id="ib0008" file="imgb0008.tif" wi="12" he="8" img-content="math" img-format="tif" inline="yes"/></maths> and validation <maths id="math0009" num=""><math display="inline"><mrow><msubsup><mfenced open="{" close="}"><msup><mi>U</mi><mi>s</mi></msup></mfenced><mrow><mi>s</mi><mo>=</mo><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mi>M</mi></msubsup></mrow></math><img id="ib0009" file="imgb0009.tif" wi="15" he="8" img-content="math" img-format="tif" inline="yes"/></maths> data sets. A Recurrent Neural Network <i>RNN</i> is trained on the training set and then applied for predicting system outputs <i><o ostyle="single">z</o></i><sub>j</sub> to given inputs <i>u</i><sub>j</sub> : <maths id="math0010" num=""><math display="block"><mrow><msubsup><mfenced open="{" close="}"><msub><mrow><mover><mi>z</mi><mrow><mo>‾</mo></mrow></mover></mrow><mi>j</mi></msub></mfenced><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup><mo>=</mo><mi mathvariant="italic">RNN</mi><mfenced><msubsup><mfenced open="{" close="}"><msub><mi>u</mi><mi>j</mi></msub></mfenced><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup></mfenced></mrow></math><img id="ib0010" file="imgb0010.tif" wi="39" he="9" img-content="math" img-format="tif"/></maths><!-- EPO <DP n="9"> --><br>

**[0033]**&nbsp;&nbsp;The trained Recurrent Neural Network RNN is then applied to the validation data set and the predicted validation output is compared to the measured validation outputs to create an empirical covariance matrix <i><o ostyle="single">Q</o><sub>k</sub></i> for the expected error of the RNN prediction for each time step <i>k</i>.<br>

<br><br>Combination<br><br>
**[0034]**&nbsp;&nbsp;Finally, the method suggested herein combines the state-space and data-driven models to produce a joint state prediction <maths id="math0011" num=""><math display="inline"><mrow><msubsup><mfenced open="{" close="}"><msub><mrow><mover><mi>x</mi><mrow><mo>‾</mo></mrow></mover></mrow><mi>j</mi></msub></mfenced><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup></mrow></math><img id="ib0011" file="imgb0011.tif" wi="11" he="8" img-content="math" img-format="tif" inline="yes"/></maths> to a given control input <maths id="math0012" num=""><math display="inline"><mrow><msubsup><mfenced open="{" close="}"><msub><mi>u</mi><mi>j</mi></msub></mfenced><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup></mrow></math><img id="ib0012" file="imgb0012.tif" wi="11" he="9" img-content="math" img-format="tif" inline="yes"/></maths> and initial state <i>x</i><sub>0</sub> :
<ul id="ul0004" list-style="dash" compact="compact">
<li>The control input is fed into the neural network model and produces predicted outputs <maths id="math0013" num=""><math display="inline"><mrow><msubsup><mfenced open="{" close="}"><msub><mrow><mover><mi>z</mi><mrow><mo>‾</mo></mrow></mover></mrow><mi>j</mi></msub></mfenced><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup></mrow></math><img id="ib0013" file="imgb0013.tif" wi="11" he="9" img-content="math" img-format="tif" inline="yes"/></maths> and covariances <maths id="math0014" num=""><math display="inline"><mrow><msubsup><mfenced open="{" close="}"><msub><mrow><mover><mi>Q</mi><mrow><mo>‾</mo></mrow></mover></mrow><mi>j</mi></msub></mfenced><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup><mn>.</mn></mrow></math><img id="ib0014" file="imgb0014.tif" wi="14" he="9" img-content="math" img-format="tif" inline="yes"/></maths></li>
<li>The Kalman-filter algorithm is applied iteratively to the state estimates where in each time step, <i>z<sub>k</sub></i> is replaced by <i><o ostyle="single">z</o><sub>k</sub></i> and <i>Q<sub>k</sub></i> by <i><o ostyle="single">Q</o><sub>k</sub>.</i></li>
</ul><br>

**[0035]**&nbsp;&nbsp;The computationally expensive task of training the Recurrent Neural Network (RNN) may be carried out offline in advance, while the state-prediction only uses a forward evaluation of the RNN and the Kalman-filter equations, which can be solved numerically with very low computational costs. Hence, in most cases the proposed state prediction method is expected to be calculated faster than real-time.<br>

**[0036]**&nbsp;&nbsp;<figref idref="f0003">Figure 3</figref> shows a flow chart of an exemplary method that may be based on the above described methods 100 and/or 200 of <figref idref="f0001">Figures 1</figref> and <figref idref="f0002">2</figref>, respectively. In a step 305, a state space model of behaviour of a physical system is provided, the model including covariances for state transition and measurement errors. In a step 310, a data based regression model for prediction of state variables of the physical system is provided.<!-- EPO <DP n="10"> --><br>

**[0037]**&nbsp;&nbsp;The two models have different strengths and weaknesses (or limitations) as was discussed above. In a step 315, a state vector comprising state variables of the physical system is observed. Similarly, in a step 320, a prediction vector of state variables based on the state vector is determined using the regression model.<br>

**[0038]**&nbsp;&nbsp;Results of the two models are then combined in a step 325 by using a Bayesian filter. The method 300 may start over and loop over steps 315 - 325 for continuous operation.<br>

**[0039]**&nbsp;&nbsp;Figure 4 shows a depiction 400 of a physical system 405 that is represented by an exemplary asynchronous electric motor, although present invention is not limited to electric machinery. The electric motor 405 may be a large drive motor for an elevator, a belt conveyor or a sewage pump, potentially with a maximum power in the range of up to 100 kW or more. The motor 405 comprises a stator 410 and a rotor 415. On the motor 405 there may be one or more sensors 420 to pick up conditions of motor 405, like a temperature in a predetermined position, a rotating speed, a provided torque or an electric current.<br>

**[0040]**&nbsp;&nbsp;Via an optional first interface 425 the measurements are made available to an apparatus 430 that is adapted to make a state variable forecast based on the received measurements. The apparatus 430 comprises processing means 435 which may comprise a programmable microcomputer or microcontroller. The processing means 435 is adapted to carry out a method for state variable prediction, especially according to method 300. Features or advantages of the method 300 may be applied to the system 405 or vice versa. Carrying out said method 300 may comprise execution of a computer program product with program code means. The determined forecast for one or more state variables may be provided via an optional second interface 440.<!-- EPO <DP n="11"> --><br>

**[0041]**&nbsp;&nbsp;The forecast may also be used for protection of motor 405. Should the forecast state indicate a pending critical situation of motor 405, say, an overheating about to take place, electrical power to the motor 405 may be temporarily reduced or cut. To determine a critical situation, a forecast state may be compared against a predetermined threshold. Other approaches comprise observation of the rising speed of a predicted state variable or a combination of several state variables fulfilling a predetermined condition. The condition may for instance be given in the form of a predetermined polynomial, the value of which may exceed a predetermined threshold upon a pending critical situation. The apparatus 430 may also be adapted to output a signal that hints at the pending critical situation, or activate means to prevent the situation.<br>

**[0042]**&nbsp;&nbsp;Even though present invention has been illustrated and explained in detail above with reference to the preferred embodiments, the invention is not to be construed as limited to the given examples. Variants or alternate combinations of features given in different embodiments may be derived by a subject matter expert without exceeding the scope of present invention.<br>

***
### **Claims**<br><br>
1. Method (300), the method comprising the following steps:<br><claim-text>- providing (305) a state space model of behaviour of a physical system, the model including covariances for state transition and measurement errors;</claim-text><br><claim-text>- providing (310) a data based regression model for prediction of state variables of the physical system;</claim-text><br><claim-text>- observing (315) a state vector comprising state variables of the physical system;</claim-text><br><claim-text>- determining (320) a prediction vector of state variables based on the state vector, using the regression model; and</claim-text><br><claim-text>- combining (325) information from the state space model with predictions from the regression model through a Bayesian filter.</claim-text><br><br>
1. Method (300) according to claim 1, wherein the Bayesian filter is realized by a Kalman filter.<br><br>
1. Method (300) according to claim 1, wherein the Bayesian filter is realized by an Extended Kalman filter.<br><br>
1. Method (300) according to claim 1, wherein the Bayesian filter comprises a particle filter.<br><br>
1. Method (300) according to one of the previous claims, wherein the regression model comprises a trained Recurrent Neural Network.<br><br>
1. Method (300) according to claim 5, wherein the physical system is time continuous, the Recurrent Neural Network is interpolated between discrete time steps and the Bayesian filter comprises a Continuous Kalman Filter.<!-- EPO <DP n="13"> --><br><br>
1. Apparatus (430), comprising the following elements:<br><claim-text>- an interface (425) for observing a state vector comprising state variables in a physical system;</claim-text><br><claim-text>- processing means (435), adapted to carry out a method (200) according to one of the above claims.</claim-text><!-- EPO <DP n="14"> --><br><br>
***
**Amended claims in accordance with Rule 137(2) EPC.**<br><br>
Method (300) for predicting a state of a physical system, the method comprising the following steps:<br><claim-text>- providing (305) a state space model of behaviour of a physical system, the model including covariances for state transition and measurement errors;</claim-text><br><claim-text>- providing (310) a data based regression model for prediction of state variables of the physical system;</claim-text><br><claim-text>- observing (315) a state vector comprising state variables of the physical system;</claim-text><br><claim-text>- determining (320) a prediction vector of state variables based on the state vector, using the regression model; and</claim-text><br><claim-text>- combining (325) information from the state space model with predictions from the regression model through a Bayesian filter.</claim-text><br><br>
Method (300) according to claim 1, wherein the Bayesian filter is realized by a Kalman filter.<br><br>
Method (300) according to claim 1, wherein the Bayesian filter is realized by an Extended Kalman filter.<br><br>
Method (300) according to claim 1, wherein the Bayesian filter comprises a particle filter.<br><br>
Method (300) according to one of the previous claims, wherein the regression model comprises a trained Recurrent Neural Network.<br><br>
Method (300) according to claim 5, wherein the physical system is time continuous, the Recurrent Neural Network is interpolated between discrete time steps and the Bayesian filter comprises a Continuous Kalman Filter.<!-- EPO <DP n="15"> --><br><br>
Apparatus (430) for predicting a state of a physical system, comprising the following elements:<br><claim-text>- an interface (425) for observing a state vector comprising state variables in a physical system;</claim-text><br><claim-text>- processing means (435), adapted to carry out a method (200) according to one of the above claims.</claim-text><br><br>
***